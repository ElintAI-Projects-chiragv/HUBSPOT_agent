{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "25d72636",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, TypedDict\n",
    "from langgraph.graph import StateGraph, END\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "import pandas as pd\n",
    "from IPython.display import display, Image\n",
    "from langchain_core.runnables.graph import MermaidDrawMethod\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import uuid\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import List, TypedDict\n",
    "from urllib.request import urlopen \n",
    "import json \n",
    "# import praw\n",
    "# from prawcore.exceptions import ResponseException\n",
    "import requests\n",
    "from datetime import datetime, timedelta\n",
    "from langgraph.graph import StateGraph, START,END\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5daf80fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "os.environ['GROQ_API_KEY'] = ''\n",
    "from langchain_groq import ChatGroq\n",
    "llm = ChatGroq(\n",
    "    model=\"llama-3.3-70b-versatile\",\n",
    "    temperature=0,\n",
    "    max_tokens=None,\n",
    "    timeout=None,\n",
    "    max_retries=2,\n",
    "    # other params...\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d22d1497",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import TypedDict\n",
    "\n",
    "class HubspotAgent(TypedDict):\n",
    "  requirememt: str\n",
    "  deal_price: str\n",
    "  \n",
    "  initial_greet: str\n",
    "  \n",
    "  \n",
    "  qualified:str\n",
    "  polite_reply: str\n",
    "  price_ask_str: str\n",
    "  price: int\n",
    "  scheduler: str\n",
    "  assign: str\n",
    "  esclator:str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a1b4a2fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inital_greet(state:HubspotAgent):\n",
    "    \n",
    "    prompt = f'''\n",
    "    I am a CTO at a AI consulting company named as 'Elint Data' and I have a lead on hubspot for which i want to draft an initial email stating we do the following services\n",
    "\n",
    "    1) Agentic AI\n",
    "    2) AI Red Teaming\n",
    "    3)DevSecOps\n",
    "    4)  High-Performance Computing\n",
    "\n",
    "    I dont know much about thier company\n",
    "    '''\n",
    "        \n",
    "    response = llm.invoke(prompt)\n",
    "    \n",
    "    return {'initial_greet':response}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a480ad06",
   "metadata": {},
   "outputs": [],
   "source": [
    "def qualifier(state:HubspotAgent):\n",
    "    text = state['requirememt']\n",
    "    prompt = f'''you are a sales agent. you have a requirement from a customer. you need to qualify that can we do the required task.\n",
    "    \n",
    "    we are a software company. we are providing 4 services.\n",
    "    1. Agentic AI\n",
    "    2. AI Red Teaming\n",
    "    3. DevSecOps\n",
    "    4. High-Performance Computing\n",
    "    \n",
    "    \n",
    "    \n",
    "    the requirement is :{text}\n",
    "    reply with just yes or no.\n",
    "    '''\n",
    "    \n",
    "    response = llm.invoke(prompt)\n",
    "    response = response.lower()\n",
    "    \n",
    "    return {'qualified':response}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d315aa4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def second_stage_reply(state:HubspotAgent):\n",
    "    quali = state['qualified']\n",
    "    if quali == 'yes':\n",
    "        prompt = f'''you are a sales agent. you have to politely reply to a customer.\n",
    "        That we can do the required project and we will assign a team to work on it.\n",
    "        '''\n",
    "        response1 = llm.invoke(prompt)\n",
    "        return {'polite_reply':response1,'price_ask_str':'None'}\n",
    "    else:\n",
    "        prompt = f'''you are a sales agent. you have to politely reply to a customer.\n",
    "        to ask for their budget of the project.\n",
    "        '''\n",
    "        response2 = llm.invoke(prompt)\n",
    "        return {'price_ask_str':response2,'polite_reply':'None'}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "65de143f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def deal_price_extractor(state:HubspotAgent):\n",
    "    text = state['deal_price']\n",
    "    prompt = f'''\n",
    "    you are a sales agent. you have to extract the price from the customer.\n",
    "    the customer has given a deal price of {text}\n",
    "    '''\n",
    "    \n",
    "    response = llm.invoke(prompt)\n",
    "    response = response.lower()\n",
    "    \n",
    "    return {'scheduler':response}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3723839a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def schedule(state:HubspotAgent):\n",
    "\n",
    "\n",
    "    prompt = f'''\n",
    "    you are a sales agent. you have to schedule a meeting with the customer.\n",
    "    for the requirement of {state['requirememt']} for tomorrow at 10 am.\n",
    "    '''\n",
    "    \n",
    "    response = llm.invoke(prompt)\n",
    "    \n",
    "    return {'price':response}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0823d8b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def assigner(state:HubspotAgent):\n",
    "    prompt = f'''\n",
    "    you are a sales agent. you have to assign a new project to a team member chirag.\n",
    "    for the requirement of {state['requirememt']} and a meeting has been set for tomorrow at 10 am with the client.\n",
    "    also ask chirag if he is can take up the project or not.\n",
    "    '''\n",
    "    response = llm.invoke(prompt)\n",
    "    \n",
    "    return {'assign':response}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3526f69d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, Image as PILImage\n",
    "\n",
    "workflow = StateGraph(HubspotAgent)\n",
    "\n",
    "\n",
    "workflow.add_node(\"inital_greet\", inital_greet)\n",
    "workflow.add_node(\"qualifier\", qualifier)\n",
    "workflow.add_node(\"second_stage_reply\", second_stage_reply)\n",
    "workflow.add_node(\"deal_price_extractor\", deal_price_extractor)\n",
    "workflow.add_node(\"schedule\", schedule) \n",
    "workflow.add_node(\"assigner\", assigner) \n",
    "\n",
    "\n",
    "workflow.set_entry_point(\"inital_greet\")\n",
    "workflow.add_edge(\"inital_greet\", \"qualifier\")\n",
    "workflow.add_edge(\"qualifier\", \"second_stage_reply\")\n",
    "workflow.add_edge(\"qualifier\", END)\n",
    "\n",
    "workflow.add_edge(\"second_stage_reply\", \"deal_price_extractor\") \n",
    "workflow.add_edge(\"deal_price_extractor\", \"schedule\") \n",
    "workflow.add_edge(\"deal_price_extractor\", \"assigner\")\n",
    "workflow.add_edge(\"schedule\", END)\n",
    "workflow.add_edge(\"assigner\", END)\n",
    "\n",
    "\n",
    "\n",
    "memory = MemorySaver()\n",
    "\n",
    "graph_plan = workflow.compile(checkpointer=memory)\n",
    "# display(Image(graph_plan.get_graph(xray=1).draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1c461a0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---\n",
      "config:\n",
      "  flowchart:\n",
      "    curve: linear\n",
      "---\n",
      "graph TD;\n",
      "\t__start__([<p>__start__</p>]):::first\n",
      "\tinital_greet(inital_greet)\n",
      "\tqualifier(qualifier)\n",
      "\tsecond_stage_reply(second_stage_reply)\n",
      "\tdeal_price_extractor(deal_price_extractor)\n",
      "\tschedule(schedule)\n",
      "\tassigner(assigner)\n",
      "\t__end__([<p>__end__</p>]):::last\n",
      "\t__start__ --> inital_greet;\n",
      "\tdeal_price_extractor --> assigner;\n",
      "\tdeal_price_extractor --> schedule;\n",
      "\tinital_greet --> qualifier;\n",
      "\tqualifier --> second_stage_reply;\n",
      "\tsecond_stage_reply --> deal_price_extractor;\n",
      "\tassigner --> __end__;\n",
      "\tschedule --> __end__;\n",
      "\tclassDef default fill:#f2f0ff,line-height:1.2\n",
      "\tclassDef first fill-opacity:0\n",
      "\tclassDef last fill:#bfb6fc\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(graph_plan.get_graph().draw_mermaid())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "21b44166",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'CompiledStateGraph' object has no attribute 'run'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 15\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Execute the compiled workflow graph with a sample state\u001b[39;00m\n\u001b[0;32m      2\u001b[0m sample_state \u001b[38;5;241m=\u001b[39m HubspotAgent(\n\u001b[0;32m      3\u001b[0m     requirememt\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDevelop an AI-based chatbot\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m      4\u001b[0m     deal_price\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m5000 USD\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     12\u001b[0m     esclator\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     13\u001b[0m )\n\u001b[1;32m---> 15\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mgraph_plan\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m(sample_state)\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28mprint\u001b[39m(result)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'CompiledStateGraph' object has no attribute 'run'"
     ]
    }
   ],
   "source": [
    "# Execute the compiled workflow graph with a sample state\n",
    "sample_state = HubspotAgent(\n",
    "    requirememt=\"Develop an AI-based chatbot\",\n",
    "    deal_price=\"5000 USD\",\n",
    "    initial_greet=\"\",\n",
    "    qualified=\"\",\n",
    "    polite_reply=\"\",\n",
    "    price_ask_str=\"\",\n",
    "    price=0,\n",
    "    scheduler=\"\",\n",
    "    assign=\"\",\n",
    "    esclator=\"\"\n",
    ")\n",
    "\n",
    "result = graph_plan.run(sample_state)\n",
    "print(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
